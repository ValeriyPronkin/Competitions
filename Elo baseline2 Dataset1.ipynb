{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import gc\nimport logging #библиотека для удобного ведения логов в Python\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n#settings\nwarnings.filterwarnings('ignore')\nnp.random.seed(2018)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98f304892e1ddaa225a48a1f70420b9ac790f63c"
      },
      "cell_type": "code",
      "source": "#logger\ndef get_logger():\n    FORMAT = '[%(levelname)s]%(asctime)s:%(name)s:%(message)s'\n    logging.basicConfig(format=FORMAT) #в настройки логера передать уровень выводимых ошибок\n    logger = logging.getLogger('main')\n    logger.setLevel(logging.DEBUG) # Сообщение отладочное\n    return logger",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "799f93036878673407b5f8b02ea3cc3eb58f06c2"
      },
      "cell_type": "code",
      "source": "logger = get_logger()\n#load data\nlogger.info('Start read data')\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\nhistorical_trans_df = pd.read_csv('../input/historical_transactions.csv')\nnew_merchant_trans_df = pd.read_csv('../input/new_merchant_transactions.csv')\nmerchants = pd.read_csv('../input/merchants.csv')\n#merchants = pd.read_csv('../input/merchants.csv', skiprows=lambda i: skip_func(i,p=1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a13665c71a7bb900453aa2c8f5fecddcb58140b"
      },
      "cell_type": "code",
      "source": "def print_null(df):\n    for col in df:\n        if df[col].isnull().any():\n            print('%s has %.0f null values: %.3f%%'%(col, df[col].isnull().sum(), df[col].isnull().sum()/df[col].count()*100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb181b43d0740dcabab9f995e52f07a76897f763"
      },
      "cell_type": "code",
      "source": "def impute_na(X_train, df, variable):\n    # make temporary df copy\n    temp = df.copy()\n    \n    # extract random from train set to fill the na\n    random_sample = X_train[variable].dropna().sample(temp[variable].isnull().sum(), random_state=0, replace=True)\n    \n    # pandas needs to have the same index in order to merge datasets\n    random_sample.index = temp[temp[variable].isnull()].index\n    temp.loc[temp[variable].isnull(), variable] = random_sample\n    return temp[variable]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd2d91608b198948c3f726b013d603c08bae9d12"
      },
      "cell_type": "code",
      "source": "# Clipping outliers\ndef clipping_outliers(X_train, df, var):\n    IQR = X_train[var].quantile(0.75)-X_train[var].quantile(0.25)\n    lower_bound = X_train[var].quantile(0.25) - 6*IQR\n    upper_bound = X_train[var].quantile(0.75) + 6*IQR\n    no_outliers = len(df[df[var]>upper_bound]) + len(df[df[var]<lower_bound])\n    print('There are %i outliers in %s: %.3f%%' %(no_outliers, var, no_outliers/len(df)))\n    df[var] = df[var].clip(lower_bound, upper_bound)\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ef5b53260fac250f50621c190ff3e70c6c58152"
      },
      "cell_type": "code",
      "source": "def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f1b2999e61164af602fd8c4a782131a6572f05a"
      },
      "cell_type": "code",
      "source": "merchants_df = pd.read_csv('../input/merchants.csv')\nmerchants_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74b466afcfff36c7402fd3d6ff9f980a5893f2be"
      },
      "cell_type": "code",
      "source": "merchants_df = merchants_df.replace([np.inf,-np.inf], np.nan)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ecf3e8f0e59140ad9da19d8aa967bce4f3a6776"
      },
      "cell_type": "code",
      "source": "print_null(merchants_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "642c2960d79c8824136879d059b9f6072c04bb72"
      },
      "cell_type": "code",
      "source": "# Average sales null\nnull_cols = ['avg_purchases_lag3','avg_sales_lag3', 'avg_purchases_lag6','avg_sales_lag6','avg_purchases_lag12','avg_sales_lag12']\nfor col in null_cols:\n    merchants_df[col] = merchants_df[col].fillna(merchants_df[col].mean())\n\n# Category 2\nmerchants_df['category_2'] = impute_na(merchants_df, merchants_df, 'category_2')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a3a2791b7cd0bf39e02b65620fc10a933f79c4a"
      },
      "cell_type": "code",
      "source": "merchants_df['most_recent_sales_range'].value_counts().sort_values(ascending=False).values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37f5fa4a510ed8f1a012b868a66ee3111994728c"
      },
      "cell_type": "code",
      "source": "merchants_df['most_recent_purchases_range'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a2b95dc9cdffc5aaed1791db38b45a912bb1ad2"
      },
      "cell_type": "code",
      "source": "# Sales cut Сокращение продаж\nsales_cut = merchants_df['most_recent_sales_range'].value_counts().sort_values(ascending=False).values\nsales_cut = sales_cut/np.sum(sales_cut)\nfor i in range(1,len(sales_cut)):\n    sales_cut[i] = sales_cut[i]+sales_cut[i-1]\n    \n# Purchases cut Покупки сокращены\npurchases_cut = merchants_df['most_recent_purchases_range'].value_counts().sort_values(ascending=False).values\npurchases_cut = purchases_cut/np.sum(purchases_cut)\nfor i in range(1,len(purchases_cut)):\n    purchases_cut[i] = purchases_cut[i]+purchases_cut[i-1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7940c53c43dc4f97fae627cff9f3b36f85a550c"
      },
      "cell_type": "code",
      "source": "sales_cut, purchases_cut",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7b6eeabca0c09c79cfa050273dc71a0729412f5"
      },
      "cell_type": "code",
      "source": "merchants_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cfaebb431ddb63766a4846a59f4a42713d2f567a"
      },
      "cell_type": "code",
      "source": "merchants_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c00c995537a0682fb5521ef3eb8bd27f43be04e"
      },
      "cell_type": "code",
      "source": "# Discretize data Дискретизировать данные\ndiscretize_cols = ['avg_purchases_lag3','avg_sales_lag3', 'avg_purchases_lag6','avg_sales_lag6','avg_purchases_lag12','avg_sales_lag12']\n\nfor col in discretize_cols:\n    categories = pd.qcut(merchants_df[col].values,sales_cut, duplicates='raise').categories.format()\n    merchants_df[col], intervals = pd.qcut(merchants_df[col], 5, labels=['A','B','C','D','E'], retbins=True, duplicates='raise')\n    print('Discretize for %s:'%col)\n    print(categories)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f0591d57e60267e6ad9cb87931e4c341a20e28c5"
      },
      "cell_type": "code",
      "source": "merchants_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8883941cd60982c51d4409078d83375007e73f3d"
      },
      "cell_type": "code",
      "source": "# Mapping data\nmerchants_df['category_1'] = merchants_df['category_1'].map({'Y':1, 'N':0})\nmerchants_df['category_4'] = merchants_df['category_4'].map({'Y':1, 'N':0})\n\nmap_cols = discretize_cols + ['most_recent_purchases_range', 'most_recent_sales_range']\nfor col in map_cols:\n    merchants_df[col] = merchants_df[col].map({'A':5,'B':4,'C':3,'D':2,'E':1})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5837e7610144f7ff318485191fcc8513763c457e"
      },
      "cell_type": "code",
      "source": "map_cols",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2ec6d7696899cf4d44aa7604cb497c3edadabeb"
      },
      "cell_type": "code",
      "source": "merchants_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fad078edd9a6ff3b6e3d06611e88c931e067cca"
      },
      "cell_type": "code",
      "source": "numeric_cols = ['numerical_1','numerical_2']+map_cols\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(12,12))\nsns.heatmap(merchants_df[numeric_cols].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('Pair-wise correlation')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b12b6dfab7ef50ab767f31944f7c4d5b9ef29325"
      },
      "cell_type": "code",
      "source": "#Обработка числовых данных\nnumerical_cols = ['numerical_1','numerical_2']\nfor col in numerical_cols:\n    merchants_df = clipping_outliers(merchants_df, merchants_df, col)\n    plt.figure()\n    sns.distplot(merchants_df[col])\nprint('Unique values:')\nprint(merchants_df[numerical_cols].nunique())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea7969fe18f15e19f13e979db92c8f394adbda0f"
      },
      "cell_type": "code",
      "source": "#После отсечения выбросов в этих двух столбцах осталось только 5 уникальных значений. \n#Таким образом, мы отображаем их на 3 категории: самая низкая: 0, средняя: 1 и крайняя: 2\nfor col in numerical_cols:\n    b = merchants_df[col].unique()\n    merchants_df[col] = merchants_df[col].apply(lambda x: 0 if x==b[0] else (1 if x in b[1:4] else 2))                ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c5c0d5102ddffafbed6e1674bf72541bb8ced5a"
      },
      "cell_type": "code",
      "source": "merchants_df = reduce_mem_usage(merchants_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5fd2fc72daf708669b6d981c2c5f512a4b51d73d"
      },
      "cell_type": "code",
      "source": "# Rename col\nfor col in merchants_df.columns:\n    if col != 'merchant_id':\n        merchants_df = merchants_df.rename(index=str, columns={col:'mer_'+col})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d54ef762437d0dc25f145b0040af975583641d7"
      },
      "cell_type": "code",
      "source": "merchants_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f6e7fd7f6b687a9321a5fb766782ef1d99429d8"
      },
      "cell_type": "markdown",
      "source": "min_amount = historical_trans_df.purchase_amount.min()\nhistorical_trans_df.purchase_amount = historical_trans_df.purchase_amount.apply(lambda x: x-min_amount+1)\nmin_amount = new_merchant_trans_df.purchase_amount.min()\nnew_merchant_trans_df.purchase_amount = new_merchant_trans_df.purchase_amount.apply(lambda x: x-min_amount+1)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a5101693a321c1359b3a57a24ddc41c03ef66bc"
      },
      "cell_type": "code",
      "source": "#process NAs\nlogger.info('Start processing NAs')\n#process NA2 for transactions\nfor df in [historical_trans_df, new_merchant_trans_df]:\n    df['category_2'].fillna(1.0,inplace=True)\n    df['category_3'].fillna('A',inplace=True)\n    df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True) #historical_trans_df.merchant_id.describe().top\n#define function for aggregation\ndef create_new_columns(name,aggs):\n    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8b0f51ae6e9d61e2462156546c3eb7d5abbade1"
      },
      "cell_type": "code",
      "source": "# Merge with merchant data\nhistorical_trans_df = pd.merge(historical_trans_df, merchants_df, how='left', left_on='merchant_id', right_on='merchant_id')\n#new_historical_trans_df = pd.merge(new_historical_trans_df, merchants_df, how='left', left_on='merchant_id', right_on='merchant_id')\n\ndel merchants_df\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35b68d6a2cfad5fb3caf46e03af3be752b63fe43"
      },
      "cell_type": "code",
      "source": "historical_trans_df = reduce_mem_usage(historical_trans_df)\nhistorical_trans_df = historical_trans_df.drop(columns=['mer_city_id', 'mer_state_id', 'mer_category_1', 'mer_category_2',\n                          'mer_merchant_category_id','mer_subsector_id'])\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc000ae16c4df8f45935c04c645626afa424a492"
      },
      "cell_type": "code",
      "source": "logger.info('process historical and new merchant datasets')\nfor df in [historical_trans_df, new_merchant_trans_df]:\n    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n    df['year'] = df['purchase_date'].dt.year\n    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n    df['month'] = df['purchase_date'].dt.month\n    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n    df['hour'] = df['purchase_date'].dt.hour\n    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n    df['category_3'] = df['category_3'].map({'A':0, 'B':1, 'C':2}) \n    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30 #Кол-во дней с покупки\n    df['month_diff'] += df['month_lag']\n    df['is_month_start'] = df['purchase_date'].dt.is_month_start.apply(lambda x: 1 if x == 'True' else 0)#map({'False':0, 'True':1})\n    df['is_month_end'] = df['purchase_date'].dt.is_month_end.apply(lambda x: 1 if x == 'True' else 0)#.map({'False':0, 'True':1})\n    #Черная пятница\n    df['weeks_to_BFriday'] = ((pd.to_datetime('2017-11-25') - df['purchase_date']).dt.days//7).apply(lambda x: x if x>=0 and x<=3 else 3)\n    #Рождество\n    df['weeks_to_Xmas_2017'] = ((pd.to_datetime('2017-12-25') - df['purchase_date']).dt.days//7).apply(lambda x: x if x>=0 and x<=8 else 8)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36e73df0cc9b6753eaed8dacd383582f659e752e"
      },
      "cell_type": "code",
      "source": "historical_trans_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3ef7534a23b4e3d3e3e6a6ab96877e25694b9b1"
      },
      "cell_type": "code",
      "source": "#define aggregations with historical_trans_df\nlogger.info('Aggregate historical trans')\naggs = {}\n\nfor col in ['subsector_id','merchant_id','merchant_category_id']:\n    aggs[col] = ['nunique']\nfor col in ['month', 'hour', 'weekofyear', 'dayofweek', 'year']:\n    aggs[col] = ['nunique', 'mean', 'min', 'max']\n    \naggs['purchase_amount'] = ['sum','max','min','mean','var']\naggs['installments'] = ['sum','max','min','mean','var']\naggs['purchase_date'] = ['max','min','count']\naggs['month_lag'] = ['max','min','mean','var']\naggs['month_diff'] = ['mean', 'min', 'max', 'var']\naggs['authorized_flag'] = ['sum', 'mean', 'min', 'max']\naggs['weekend'] = ['sum', 'mean', 'min', 'max']\naggs['category_1'] = ['sum', 'mean', 'min']\naggs['category_2'] = ['sum', 'mean', 'min']\naggs['category_3'] = ['sum', 'mean', 'min']\naggs['card_id'] = ['size', 'count']\naggs['weeks_to_BFriday'] = ['sum', 'mean', 'min', 'max']\naggs['weeks_to_Xmas_2017'] = ['sum', 'mean', 'min', 'max']\naggs['is_month_start'] = ['sum', 'mean', 'min', 'max']\naggs['is_month_end'] = ['sum', 'mean', 'min', 'max']\n\nfor col in historical_trans_df.columns:\n    if 'mer_' in col:\n        #print (i)\n        aggs[col] = ['nunique', 'mean', 'min', 'max', 'count']\n\nfor col in ['category_2','category_3']:\n    historical_trans_df[col+'_mean'] = historical_trans_df.groupby([col])['purchase_amount'].transform('mean')\n    historical_trans_df[col+'_min'] = historical_trans_df.groupby([col])['purchase_amount'].transform('min')\n    historical_trans_df[col+'_max'] = historical_trans_df.groupby([col])['purchase_amount'].transform('max')\n    historical_trans_df[col+'_sum'] = historical_trans_df.groupby([col])['purchase_amount'].transform('sum')\n    aggs[col+'_mean'] = ['mean']    \n\nnew_columns = create_new_columns('hist',aggs)\nhistorical_trans_group_df = historical_trans_df.groupby('card_id').agg(aggs)\nhistorical_trans_group_df.columns = new_columns\nhistorical_trans_group_df.reset_index(drop=False,inplace=True)\nhistorical_trans_group_df['hist_purchase_date_diff'] = (historical_trans_group_df['hist_purchase_date_max'] - historical_trans_group_df['hist_purchase_date_min']).dt.days\nhistorical_trans_group_df['hist_purchase_date_average'] = historical_trans_group_df['hist_purchase_date_diff']/historical_trans_group_df['hist_card_id_size']\nhistorical_trans_group_df['hist_purchase_date_uptonow'] = (datetime.datetime.today() - historical_trans_group_df['hist_purchase_date_max']).dt.days\nhistorical_trans_group_df['hist_purchase_date_uptomin'] = (datetime.datetime.today() - historical_trans_group_df['hist_purchase_date_min']).dt.days\n#merge with train, test\ntrain_df = train_df.merge(historical_trans_group_df,on='card_id',how='left')\ntest_df = test_df.merge(historical_trans_group_df,on='card_id',how='left')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b777aed0deb718cf505e5842cd230270073b06c0"
      },
      "cell_type": "code",
      "source": "#cleanup memory\ndel historical_trans_group_df; \ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b958823e2e1897bd29d751df9777f55074756da"
      },
      "cell_type": "code",
      "source": "#define aggregations with new_merchant_trans_df \nlogger.info('Aggregate new merchant trans')\naggs = {}\nfor col in ['subsector_id','merchant_id','merchant_category_id']:\n    aggs[col] = ['nunique']\nfor col in ['month', 'hour', 'weekofyear', 'dayofweek', 'year']:\n    aggs[col] = ['nunique', 'mean', 'min', 'max']\n\n    \naggs['purchase_amount'] = ['sum','max','min','mean','var','count']\naggs['installments'] = ['sum','max','min','mean','var']\naggs['purchase_date'] = ['max','min', 'count']\naggs['month_lag'] = ['max','min','mean','var']\naggs['month_diff'] = ['mean', 'max', 'min', 'var']\naggs['weekend'] = ['sum', 'mean', 'min']\naggs['category_1'] = ['sum', 'mean', 'min']\naggs['category_2'] = ['sum', 'mean', 'min']\naggs['category_3'] = ['sum', 'mean', 'min']\naggs['card_id'] = ['size', 'count']\naggs['is_month_start'] = ['sum', 'mean', 'min', 'max']\naggs['is_month_end'] = ['sum', 'mean', 'min', 'max']\naggs['weeks_to_BFriday'] = ['sum', 'mean', 'min', 'max']\naggs['weeks_to_Xmas_2017'] = ['sum', 'mean', 'min', 'max']\n\nfor col in ['category_2','category_3']:\n    new_merchant_trans_df[col+'_mean'] = new_merchant_trans_df.groupby([col])['purchase_amount'].transform('mean')\n    new_merchant_trans_df[col+'_min'] = new_merchant_trans_df.groupby([col])['purchase_amount'].transform('min')\n    new_merchant_trans_df[col+'_max'] = new_merchant_trans_df.groupby([col])['purchase_amount'].transform('max')\n    new_merchant_trans_df[col+'_sum'] = new_merchant_trans_df.groupby([col])['purchase_amount'].transform('sum')\n    aggs[col+'_mean'] = ['mean']\n\n\n    \nnew_columns = create_new_columns('new_hist',aggs)\nnew_merchant_trans_group_df = new_merchant_trans_df.groupby('card_id').agg(aggs)\nnew_merchant_trans_group_df.columns = new_columns\nnew_merchant_trans_group_df.reset_index(drop=False,inplace=True)\nnew_merchant_trans_group_df['new_hist_purchase_date_diff'] = (new_merchant_trans_group_df['new_hist_purchase_date_max'] - new_merchant_trans_group_df['new_hist_purchase_date_min']).dt.days\nnew_merchant_trans_group_df['new_hist_purchase_date_average'] = new_merchant_trans_group_df['new_hist_purchase_date_diff']/new_merchant_trans_group_df['new_hist_card_id_size']\nnew_merchant_trans_group_df['new_hist_purchase_date_uptonow'] = (datetime.datetime.today() - new_merchant_trans_group_df['new_hist_purchase_date_max']).dt.days\nnew_merchant_trans_group_df['new_hist_purchase_date_uptomin'] = (datetime.datetime.today() - new_merchant_trans_group_df['new_hist_purchase_date_min']).dt.days\n#merge with train, test\ntrain_df = train_df.merge(new_merchant_trans_group_df,on='card_id',how='left')\ntest_df = test_df.merge(new_merchant_trans_group_df,on='card_id',how='left')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8620a854c54799bd52da80ca259eff69316c0aac"
      },
      "cell_type": "code",
      "source": "#clean-up memory\ndel new_merchant_trans_group_df; gc.collect()\ndel historical_trans_df; gc.collect()\ndel new_merchant_trans_df; gc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0bf4c06ad646594ee05d607aa80045b114d79fc5"
      },
      "cell_type": "code",
      "source": "#process train\nlogger.info('Process train')\ntrain_df['outliers'] = 0\ntrain_df.loc[train_df['target'] < -30, 'outliers'] = 1\ntrain_df['outliers'].value_counts()\nlogger.info('Process train and test')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a35019f4b7e6228e8015bf4dfdef9bee3a51633d"
      },
      "cell_type": "code",
      "source": "## process both train and test\nfor df in [train_df, test_df]:\n    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n    df['dayofyear'] = df['first_active_month'].dt.dayofyear\n    df['quarter'] = df['first_active_month'].dt.quarter\n    df['is_month_start'] = df['first_active_month'].dt.is_month_start\n    df['month'] = df['first_active_month'].dt.month\n    df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n    df['hist_last_buy'] = (df['hist_purchase_date_max'] - df['first_active_month']).dt.days\n    df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n    df['new_hist_last_buy'] = (df['new_hist_purchase_date_max'] - df['first_active_month']).dt.days\n    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n                     'new_hist_purchase_date_min']:\n        df[f] = df[f].astype(np.int64) * 1e-9\n    df['card_id_total'] = df['new_hist_card_id_size']+df['hist_card_id_size']\n    df['card_id_cnt_total'] = df['new_hist_card_id_count']+df['hist_card_id_count']\n    df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']\n    df['purchase_amount_mean'] = df['new_hist_purchase_amount_mean']+df['hist_purchase_amount_mean']\n    df['purchase_amount_max'] = df['new_hist_purchase_amount_max']+df['hist_purchase_amount_max']\n\nfor f in ['feature_1','feature_2','feature_3']:\n    order_label = train_df.groupby([f])['outliers'].mean()\n    train_df[f] = train_df[f].map(order_label)\n    test_df[f] = test_df[f].map(order_label)\n##\n#train_columns = [c for c in train_df.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n#target = train_df['target']\n#del train_df['target']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f91a50079eaa7acd09028af776141a8cd4014a50"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3bf593341297cf43f51b7c827fa4208379831a4"
      },
      "cell_type": "code",
      "source": "train_df.to_csv(\"train_ds1.csv\", index=False)\ntest_df.to_csv(\"test_ds1.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}